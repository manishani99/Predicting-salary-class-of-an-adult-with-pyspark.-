{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row, SQLContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning with pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/guru99-edu/R-Programming/master/adult_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.addFile(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = sqlContext.read.csv(SparkFiles.get(\"adult_data.csv\"), header=True, inferSchema= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.printSchema of DataFrame[x: int, age: int, workclass: string, fnlwgt: int, education: string, educational-num: int, marital-status: string, occupation: string, relationship: string, race: string, gender: string, capital-gain: int, capital-loss: int, hours-per-week: int, native-country: string, income: string]>"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---------+------+---------+---------------+------------------+-----------------+------------+-----+------+------------+------------+--------------+--------------+------+\n",
      "|x  |age|workclass|fnlwgt|education|educational-num|marital-status    |occupation       |relationship|race |gender|capital-gain|capital-loss|hours-per-week|native-country|income|\n",
      "+---+---+---------+------+---------+---------------+------------------+-----------------+------------+-----+------+------------+------------+--------------+--------------+------+\n",
      "|1  |25 |Private  |226802|11th     |7              |Never-married     |Machine-op-inspct|Own-child   |Black|Male  |0           |0           |40            |United-States |<=50K |\n",
      "|2  |38 |Private  |89814 |HS-grad  |9              |Married-civ-spouse|Farming-fishing  |Husband     |White|Male  |0           |0           |50            |United-States |<=50K |\n",
      "+---+---+---------+------+---------+---------------+------------------+-----------------+------------+-----+------+------------+------------+--------------+--------------+------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show(2, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.drop('x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+------+------------+---------------+------------------+-----------------+------------+-----+------+------------+------------+--------------+--------------+------+\n",
      "|age|workclass|fnlwgt|education   |educational-num|marital-status    |occupation       |relationship|race |gender|capital-gain|capital-loss|hours-per-week|native-country|income|\n",
      "+---+---------+------+------------+---------------+------------------+-----------------+------------+-----+------+------------+------------+--------------+--------------+------+\n",
      "|25 |Private  |226802|11th        |7              |Never-married     |Machine-op-inspct|Own-child   |Black|Male  |0           |0           |40            |United-States |<=50K |\n",
      "|38 |Private  |89814 |HS-grad     |9              |Married-civ-spouse|Farming-fishing  |Husband     |White|Male  |0           |0           |50            |United-States |<=50K |\n",
      "|28 |Local-gov|336951|Assoc-acdm  |12             |Married-civ-spouse|Protective-serv  |Husband     |White|Male  |0           |0           |40            |United-States |>50K  |\n",
      "|44 |Private  |160323|Some-college|10             |Married-civ-spouse|Machine-op-inspct|Husband     |Black|Male  |7688        |0           |40            |United-States |>50K  |\n",
      "|18 |?        |103497|Some-college|10             |Never-married     |?                |Own-child   |White|Female|0           |0           |30            |United-States |<=50K |\n",
      "+---+---------+------+------------+---------------+------------------+-----------------+------------+-----+------+------------+------------+--------------+--------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show(5, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "|age|fnlwgt|\n",
      "+---+------+\n",
      "| 25|226802|\n",
      "| 38| 89814|\n",
      "| 28|336951|\n",
      "| 44|160323|\n",
      "| 18|103497|\n",
      "+---+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.select('age','fnlwgt').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Count by group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|   education|count|\n",
      "+------------+-----+\n",
      "|   Preschool|   83|\n",
      "|     1st-4th|  247|\n",
      "|     5th-6th|  509|\n",
      "|   Doctorate|  594|\n",
      "|        12th|  657|\n",
      "|         9th|  756|\n",
      "| Prof-school|  834|\n",
      "|     7th-8th|  955|\n",
      "|        10th| 1389|\n",
      "|  Assoc-acdm| 1601|\n",
      "|        11th| 1812|\n",
      "|   Assoc-voc| 2061|\n",
      "|     Masters| 2657|\n",
      "|   Bachelors| 8025|\n",
      "|Some-college|10878|\n",
      "|     HS-grad|15784|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.groupBy(\"education\").count().sort(\"count\",ascending=True).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Describe data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------+------------------+------------+------------------+--------------+----------------+------------+------------------+------+------------------+-----------------+------------------+--------------+------+\n",
      "|summary|               age|  workclass|            fnlwgt|   education|   educational-num|marital-status|      occupation|relationship|              race|gender|      capital-gain|     capital-loss|    hours-per-week|native-country|income|\n",
      "+-------+------------------+-----------+------------------+------------+------------------+--------------+----------------+------------+------------------+------+------------------+-----------------+------------------+--------------+------+\n",
      "|  count|             48842|      48842|             48842|       48842|             48842|         48842|           48842|       48842|             48842| 48842|             48842|            48842|             48842|         48842| 48842|\n",
      "|   mean| 38.64358543876172|       null|189664.13459727284|        null|10.078088530363212|          null|            null|        null|              null|  null|1079.0676262233324|87.50231358257237|40.422382375824085|          null|  null|\n",
      "| stddev|13.710509934443525|       null|105604.02542315757|        null| 2.570972755592259|          null|            null|        null|              null|  null| 7452.019057655418| 403.004552124359|12.391444024252312|          null|  null|\n",
      "|    min|                17|          ?|             12285|        10th|                 1|      Divorced|               ?|     Husband|Amer-Indian-Eskimo|Female|                 0|                0|                 1|             ?| <=50K|\n",
      "|    max|                90|Without-pay|           1490400|Some-college|                16|       Widowed|Transport-moving|        Wife|             White|  Male|             99999|             4356|                99|    Yugoslavia|  >50K|\n",
      "+-------+------------------+-----------+------------------+------------+------------------+--------------+----------------+------------+------------------+------+------------------+-----------------+------------------+--------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|      capital-gain|\n",
      "+-------+------------------+\n",
      "|  count|             48842|\n",
      "|   mean|1079.0676262233324|\n",
      "| stddev| 7452.019057655418|\n",
      "|    min|                 0|\n",
      "|    max|             99999|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.describe('capital-gain').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Crosstab computation\n",
    "#### descoptive statistics b/w 2 pairwise columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|income|\n",
      "+------+\n",
      "| <=50K|\n",
      "| <=50K|\n",
      "|  >50K|\n",
      "|  >50K|\n",
      "| <=50K|\n",
      "+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.select('income').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+----+\n",
      "|age_income|<=50K|>50K|\n",
      "+----------+-----+----+\n",
      "|        17|  595|   0|\n",
      "|        18|  862|   0|\n",
      "|        19| 1050|   3|\n",
      "|        20| 1112|   1|\n",
      "|        21| 1090|   6|\n",
      "|        22| 1161|  17|\n",
      "|        23| 1307|  22|\n",
      "|        24| 1162|  44|\n",
      "|        25| 1119|  76|\n",
      "|        26| 1068|  85|\n",
      "|        27| 1117| 115|\n",
      "|        28| 1101| 179|\n",
      "|        29| 1025| 198|\n",
      "|        30| 1031| 247|\n",
      "|        31| 1050| 275|\n",
      "|        32|  957| 296|\n",
      "|        33| 1045| 290|\n",
      "|        34|  949| 354|\n",
      "|        35|  997| 340|\n",
      "|        36|  948| 400|\n",
      "+----------+-----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.crosstab('age','income').sort(\"age_income\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = df1.drop('educational-num')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'workclass',\n",
       " 'fnlwgt',\n",
       " 'education',\n",
       " 'educational-num',\n",
       " 'marital-status',\n",
       " 'occupation',\n",
       " 'relationship',\n",
       " 'race',\n",
       " 'gender',\n",
       " 'capital-gain',\n",
       " 'capital-loss',\n",
       " 'hours-per-week',\n",
       " 'native-country',\n",
       " 'income']"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20211"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.filter(df1.age > 40).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Descriptive statistics by group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|      marital-status| avg(capital-gain)|\n",
      "+--------------------+------------------+\n",
      "|           Separated| 581.8424836601307|\n",
      "|       Never-married|  384.382639449029|\n",
      "|Married-spouse-ab...| 629.0047770700637|\n",
      "|            Divorced| 793.6755615860094|\n",
      "|             Widowed| 603.6442687747035|\n",
      "|   Married-AF-spouse|2971.6216216216217|\n",
      "|  Married-civ-spouse|1739.7006121810625|\n",
      "+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.groupby('marital-status').agg({'capital-gain': 'mean'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add age square\n",
    "age_square = df1.select(col(\"age\")**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.withColumn(\"age_square\", col(\"age\")**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- workclass: string (nullable = true)\n",
      " |-- fnlwgt: integer (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- educational-num: integer (nullable = true)\n",
      " |-- marital-status: string (nullable = true)\n",
      " |-- occupation: string (nullable = true)\n",
      " |-- relationship: string (nullable = true)\n",
      " |-- race: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- capital-gain: integer (nullable = true)\n",
      " |-- capital-loss: integer (nullable = true)\n",
      " |-- hours-per-week: integer (nullable = true)\n",
      " |-- native-country: string (nullable = true)\n",
      " |-- income: string (nullable = true)\n",
      " |-- age_square: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'workclass',\n",
       " 'fnlwgt',\n",
       " 'education',\n",
       " 'educational-num',\n",
       " 'marital-status',\n",
       " 'occupation',\n",
       " 'relationship',\n",
       " 'race',\n",
       " 'gender',\n",
       " 'capital-gain',\n",
       " 'capital-loss',\n",
       " 'hours-per-week',\n",
       " 'native-country',\n",
       " 'income',\n",
       " 'age_square']"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rearranging columns\n",
    "COLUMNS = ['age',\n",
    " 'age_square',\n",
    " 'workclass',\n",
    " 'fnlwgt',\n",
    " 'education',\n",
    " 'educational-num',\n",
    " 'marital-status',\n",
    " 'occupation',\n",
    " 'relationship',\n",
    " 'race',\n",
    " 'gender',\n",
    " 'capital-gain',\n",
    " 'capital-loss',\n",
    " 'hours-per-week',\n",
    " 'native-country',\n",
    " 'income']\n",
    "df1 = df1.select(COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(age=25, age_square=625.0, workclass=u'Private', fnlwgt=226802, education=u'11th', educational-num=7, marital-status=u'Never-married', occupation=u'Machine-op-inspct', relationship=u'Own-child', race=u'Black', gender=u'Male', capital-gain=0, capital-loss=0, hours-per-week=40, native-country=u'United-States', income=u'<=50K')"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+\n",
      "|    native-country|count|\n",
      "+------------------+-----+\n",
      "|       Philippines|  295|\n",
      "|           Germany|  206|\n",
      "|          Cambodia|   28|\n",
      "|            France|   38|\n",
      "|            Greece|   49|\n",
      "|            Taiwan|   65|\n",
      "|           Ecuador|   45|\n",
      "|         Nicaragua|   49|\n",
      "|              Hong|   30|\n",
      "|              Peru|   46|\n",
      "|             India|  151|\n",
      "|             China|  122|\n",
      "|             Italy|  105|\n",
      "|Holand-Netherlands|    1|\n",
      "|              Cuba|  138|\n",
      "|             South|  115|\n",
      "|              Iran|   59|\n",
      "|           Ireland|   37|\n",
      "|          Thailand|   30|\n",
      "|              Laos|   23|\n",
      "+------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.groupby('native-country').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluding Holand-Netherlands : It has only 1 observation. It can lead to an error during cross-validation\n",
    "df1 = df1.filter(df1[\"native-country\"] != 'Holand-Netherlands')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Building a data procesiing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar to scikit-learn, Pyspark has a pipeline API. A pipeline is very convenient to maintain the structure of the data. You push the data into the pipeline.\n",
    "# Inside the pipeline, various operations are done, the output is used to feed the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The steps to transform the data are very similar to scikit-learn. you need to:\n",
    "# Index the string to numeric\n",
    "# Create the one hot encoder\n",
    "# Transform the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two APIs do the job\n",
    "# StringIndexer, OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a). First of all, you select the string column to index. The inputCol is the name of the column in the dataset. outputCol is the new name given to the transformed column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = StringIndexer(inputCol=\"workclass\",outputCol=\"workclass_encoded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b). Fit the data and transform it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = indexer.fit(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed = model.transform(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c). Create the news columns based on the group. For instance, if there are 10 groups in the feature, the new matrix will have 10 columns, one for each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, OneHotEncoderModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(dropLast=False, inputCol=\"workclass_encoded\", outputCol=\"workclass_vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+------+------------+------------------+-----------------+------------+-----+------+------------+------------+--------------+--------------+------+-----------------+-------------+\n",
      "|age|age_square|workclass|fnlwgt|   education|    marital-status|       occupation|relationship| race|gender|capital-gain|capital-loss|hours-per-week|native-country|income|workclass_encoded|workclass_vec|\n",
      "+---+----------+---------+------+------------+------------------+-----------------+------------+-----+------+------------+------------+--------------+--------------+------+-----------------+-------------+\n",
      "| 25|     625.0|  Private|226802|        11th|     Never-married|Machine-op-inspct|   Own-child|Black|  Male|           0|           0|            40| United-States| <=50K|              0.0|(9,[0],[1.0])|\n",
      "| 38|    1444.0|  Private| 89814|     HS-grad|Married-civ-spouse|  Farming-fishing|     Husband|White|  Male|           0|           0|            50| United-States| <=50K|              0.0|(9,[0],[1.0])|\n",
      "| 28|     784.0|Local-gov|336951|  Assoc-acdm|Married-civ-spouse|  Protective-serv|     Husband|White|  Male|           0|           0|            40| United-States|  >50K|              2.0|(9,[2],[1.0])|\n",
      "| 44|    1936.0|  Private|160323|Some-college|Married-civ-spouse|Machine-op-inspct|     Husband|Black|  Male|        7688|           0|            40| United-States|  >50K|              0.0|(9,[0],[1.0])|\n",
      "| 18|     324.0|        ?|103497|Some-college|     Never-married|                ?|   Own-child|White|Female|           0|           0|            30| United-States| <=50K|              3.0|(9,[3],[1.0])|\n",
      "+---+----------+---------+------+------------+------------------+-----------------+------------+-----+------+------------+------------+--------------+--------------+------+-----------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoded = encoder.transform(indexed)\n",
    "encoded.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Encode the categorical data\n",
    "- Index the label feature\n",
    "- Add continuous variable\n",
    "- Assemble the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATE_FEATURES = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native-country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "stages = [] # stages in our Pipeline\n",
    "for categoricalCol in CATE_FEATURES:\n",
    "    stringIndexer = StringIndexer(inputCol=categoricalCol, outputCol=categoricalCol + \"Index\")\n",
    "    encoder = OneHotEncoderEstimator(inputCols=[stringIndexer.getOutputCol()],\n",
    "                                     outputCols=[categoricalCol + \"classVec\"])\n",
    "    stages += [stringIndexer, encoder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert label into label indices using the StringIndexer\n",
    "income_stringIdx =  StringIndexer(inputCol=\"income\", outputCol=\"newincome\")\n",
    "stages += [income_stringIdx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add continuous variable\n",
    "CONTI_FEATURES = ['age','age_square','fnlwgt','educational-num','capital-gain','capital-loss','hours-per-week']\n",
    "assemblerInputs = [c + \"classVec\" for c in CATE_FEATURES] + CONTI_FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble the steps\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "stages += [assembler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Push data to pipeline\n",
    "pipeline = Pipeline(stages=stages)\n",
    "pipelineModel = pipeline.fit(df1)\n",
    "model = pipelineModel.transform(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(age=25, age_square=625.0, workclass=u'Private', fnlwgt=226802, education=u'11th', educational-num=7, marital-status=u'Never-married', occupation=u'Machine-op-inspct', relationship=u'Own-child', race=u'Black', gender=u'Male', capital-gain=0, capital-loss=0, hours-per-week=40, native-country=u'United-States', income=u'<=50K', workclassIndex=0.0, workclassclassVec=SparseVector(8, {0: 1.0}), educationIndex=5.0, educationclassVec=SparseVector(15, {5: 1.0}), marital-statusIndex=1.0, marital-statusclassVec=SparseVector(6, {1: 1.0}), occupationIndex=6.0, occupationclassVec=SparseVector(14, {6: 1.0}), relationshipIndex=2.0, relationshipclassVec=SparseVector(5, {2: 1.0}), raceIndex=1.0, raceclassVec=SparseVector(4, {1: 1.0}), genderIndex=0.0, genderclassVec=SparseVector(1, {0: 1.0}), native-countryIndex=0.0, native-countryclassVec=SparseVector(40, {0: 1.0}), newincome=0.0, features=SparseVector(100, {0: 1.0, 13: 1.0, 24: 1.0, 35: 1.0, 45: 1.0, 49: 1.0, 52: 1.0, 53: 1.0, 93: 25.0, 94: 625.0, 95: 226802.0, 96: 7.0, 99: 40.0}))]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Building the classifier : Logistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To make the computation faster, you convert model to a DataFrame. You need to select newlabel and features from model using map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import DenseVector\n",
    "input_data = model.rdd.map(lambda x: (x[\"newincome\"], DenseVector(x[\"features\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = sqlContext.createDataFrame(input_data, [\"income\", \"features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|income|            features|\n",
      "+------+--------------------+\n",
      "|   0.0|[1.0,0.0,0.0,0.0,...|\n",
      "|   0.0|[1.0,0.0,0.0,0.0,...|\n",
      "+------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = df_train.randomSplit([.8,.2],seed=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+\n",
      "|income|count(income)|\n",
      "+------+-------------+\n",
      "|   0.0|        29675|\n",
      "|   1.0|         9300|\n",
      "+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.groupby('income').agg({'income': 'count'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+\n",
      "|income|count(income)|\n",
      "+------+-------------+\n",
      "|   0.0|         7479|\n",
      "|   1.0|         2387|\n",
      "+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data.groupby('income').agg({'income': 'count'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Logistic Regresoor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Initialize `lr`\n",
    "lr = LogisticRegression(labelCol=\"income\",\n",
    "                        featuresCol=\"features\",\n",
    "                        maxIter=10,\n",
    "                        regParam=0.3)\n",
    "\n",
    "# Fit the data to the model\n",
    "linearModel = lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [-0.020024313100485282,-0.17067875759794013,-0.012915023810445462,-0.17222267772956035,-0.09976851617340401,0.154794366772181,0.2361143443774587,-0.2687921350996918,-0.1973967988518051,-0.04119249600202847,0.26574649956752183,0.4347710207881013,0.007956983316968,-0.2989167581493538,0.002811702944800906,-0.3324731404712408,-0.4495839219326918,0.5510390170709929,-0.37154429813121903,-0.19305729674359548,0.6140025791271341,-0.34474797023407316,-0.39427342320353964,0.3392219150893706,-0.311304120193761,-0.19059441919350795,-0.19381640215355017,-0.15572361740267784,-0.1007681814342528,0.25394694305619214,-0.07269388888484095,0.33519114668122957,-0.08246976081806602,0.060501943006044265,-0.2939267434110623,-0.21628724748705971,-0.17317790387715357,-0.14526894316186084,-0.29078873907877717,-0.36505897781845936,0.16344754786814078,0.1351310838722112,-0.27556252650716284,0.2664732611362402,-0.16398936723206994,-0.2843802285746094,-0.2294198714460625,0.49027248116902156,0.01409359935082595,-0.15098006168024972,-0.05271844134599433,-0.23472384093801338,0.15926622420549424,0.009302223665166838,-0.36326968165648144,-0.1590721805203243,-0.013321029432129832,-0.03265780643327317,-0.20457903277560854,-0.024742366335347356,-0.25035383368049313,-0.1264129248711173,-0.17447884115525908,0.16544427143590204,-0.2375281850617204,-0.38629153983633796,-0.09650621978736083,0.13411054221333635,-0.4052941563297413,-0.066193962197755,-0.25408204694734715,-0.13366294329195272,-0.3777717830307141,-0.6179302772025455,-0.1561873325717375,-0.0738001917424913,-0.10158112902296072,0.015255238089585637,-0.03601859851728465,-0.34788775436658764,-0.4241326228665309,-0.3288524024243944,0.2676895100703056,0.11719286226107165,-0.42866046204085606,-0.27205848432217705,0.1907695990011358,-0.39707658966314935,0.2474765323929444,-0.4954982332171528,-0.38124211737891817,-0.34415901237796814,-0.1386697211646013,0.005608236331493198,4.242093364532468e-05,2.415408106843302e-07,0.053175345431659006,2.342889746688284e-05,0.00024077002372586607,0.010795202476021701]\n",
      "Intercept: -2.7419480392\n"
     ]
    }
   ],
   "source": [
    "# Print the coefficients and intercept for logistic regression\n",
    "print(\"Coefficients: \" + str(linearModel.coefficients))\n",
    "print(\"Intercept: \" + str(linearModel.intercept))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train and Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test data using the transform() method.\n",
    "predictions = linearModel.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- income: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+--------------------+\n",
      "|income|prediction|         probability|\n",
      "+------+----------+--------------------+\n",
      "|   0.0|       0.0|[0.93986414748719...|\n",
      "|   0.0|       0.0|[0.94546337719732...|\n",
      "|   0.0|       0.0|[0.93964307780162...|\n",
      "|   0.0|       0.0|[0.94024282426827...|\n",
      "|   0.0|       0.0|[0.68392879879471...|\n",
      "|   0.0|       0.0|[0.69767074646240...|\n",
      "|   0.0|       0.0|[0.72629698228672...|\n",
      "|   0.0|       0.0|[0.70474072820344...|\n",
      "|   0.0|       0.0|[0.94700376237148...|\n",
      "|   0.0|       0.0|[0.86281666810406...|\n",
      "|   0.0|       0.0|[0.85311974584505...|\n",
      "|   0.0|       0.0|[0.82182382760238...|\n",
      "|   0.0|       0.0|[0.52861371256606...|\n",
      "|   0.0|       0.0|[0.65652686349188...|\n",
      "|   0.0|       0.0|[0.68085794866931...|\n",
      "|   0.0|       0.0|[0.56875936042104...|\n",
      "|   0.0|       0.0|[0.88166191140485...|\n",
      "|   0.0|       0.0|[0.80615258609679...|\n",
      "|   0.0|       0.0|[0.84036513509636...|\n",
      "|   0.0|       0.0|[0.51313125042704...|\n",
      "+------+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "selected = predictions.select(\"income\", \"prediction\", \"probability\")\n",
    "selected.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a DataFrame with the label(income) and the `prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = predictions.select(\"income\", \"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the number of class in the label and the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+\n",
      "|income|count(income)|\n",
      "+------+-------------+\n",
      "|   0.0|         7479|\n",
      "|   1.0|         2387|\n",
      "+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm.groupby('income').agg({'income': 'count'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+\n",
      "|prediction|count(prediction)|\n",
      "+----------+-----------------+\n",
      "|       0.0|             8830|\n",
      "|       1.0|             1036|\n",
      "+----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm.groupby('prediction').agg({'prediction': 'count'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, in the test set, there is 2387 household with an income above 50k and 7479 below. The classifier, however, predicted 1036 households with income above 50k.\n",
    "\n",
    "We can compute the accuracy by computing the count when the label(income) are correctly classified over the total number of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8257652544090817"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.filter(cm.income == cm.prediction).count() / cm.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapping everything together and writing a function to compute the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 82.577%\n"
     ]
    }
   ],
   "source": [
    "def accuracy_m(model): \n",
    "    predictions = model.transform(test_data)\n",
    "    cm = predictions.select(\"income\", \"prediction\")\n",
    "    acc = cm.filter(cm.income == cm.prediction).count() / cm.count()\n",
    "    print(\"Model accuracy: %.3f%%\" % (acc * 100)) \n",
    "accuracy_m(model = linearModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.896776019636\n",
      "areaUnderROC\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Evaluate model\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "print(evaluator.setLabelCol(\"income\").evaluate(predictions))\n",
    "print(evaluator.getMetricName())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.896776019636\n"
     ]
    }
   ],
   "source": [
    "print(evaluator.evaluate(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Tune the hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "# Create ParamGrid for Cross Validation\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(lr.regParam, [0.01, 0.5])\n",
    "             .build())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "evaluating the model with using the cross valiation method with 5 folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1155.75\n"
     ]
    }
   ],
   "source": [
    "from time import *\n",
    "t0 = time()\n",
    "\n",
    "# Create 5-fold CrossValidator\n",
    "cv = CrossValidator(estimator=lr,\n",
    "                    estimatorParamMaps=paramGrid,\n",
    "                    evaluator=evaluator, numFolds=5)\n",
    "\n",
    "# Run cross validations\n",
    "cvModel = cv.fit(train_data)\n",
    "print(time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 84.715%\n"
     ]
    }
   ],
   "source": [
    "accuracy_m(model = cvModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent=u'LogisticRegression_2c978ff3de8c', name='family', doc='The name of family which is a description of the label distribution to be used in the model. Supported options: auto, binomial, multinomial.'): 'auto',\n",
       " Param(parent=u'LogisticRegression_2c978ff3de8c', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty'): 0.0,\n",
       " Param(parent=u'LogisticRegression_2c978ff3de8c', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2)'): 2,\n",
       " Param(parent=u'LogisticRegression_2c978ff3de8c', name='labelCol', doc='label column name'): 'income',\n",
       " Param(parent=u'LogisticRegression_2c978ff3de8c', name='maxIter', doc='maximum number of iterations (>= 0)'): 10,\n",
       " Param(parent=u'LogisticRegression_2c978ff3de8c', name='predictionCol', doc='prediction column name'): 'prediction',\n",
       " Param(parent=u'LogisticRegression_2c978ff3de8c', name='standardization', doc='whether to standardize the training features before fitting the model'): True,\n",
       " Param(parent=u'LogisticRegression_2c978ff3de8c', name='rawPredictionCol', doc='raw prediction (a.k.a. confidence) column name'): 'rawPrediction',\n",
       " Param(parent=u'LogisticRegression_2c978ff3de8c', name='regParam', doc='regularization parameter (>= 0)'): 0.01,\n",
       " Param(parent=u'LogisticRegression_2c978ff3de8c', name='probabilityCol', doc='Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities'): 'probability',\n",
       " Param(parent=u'LogisticRegression_2c978ff3de8c', name='threshold', doc='threshold in binary classification prediction, in range [0, 1]'): 0.5,\n",
       " Param(parent=u'LogisticRegression_2c978ff3de8c', name='tol', doc='the convergence tolerance for iterative algorithms (>= 0)'): 1e-06,\n",
       " Param(parent=u'LogisticRegression_2c978ff3de8c', name='fitIntercept', doc='whether to fit an intercept term'): True,\n",
       " Param(parent=u'LogisticRegression_2c978ff3de8c', name='featuresCol', doc='features column name'): 'features'}"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestModel = cvModel.bestModel\n",
    "bestModel.extractParamMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
